{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbtemplate import display_header, display_codetoggle, get_path\n",
    "display_header('Performanceplots.ipynb', status='draft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Where have all the photons gone, long time integrating?\n",
    "Where have all the photons gone, long time ago?\n",
    "Where have all the photons gone?\n",
    "Obscuring structures picked them one by one.\n",
    "```\n",
    "\n",
    "## Goal\n",
    "\n",
    "In the early phases of the planning the Arcus project predicted effective areas based on a spread sheet that simply took the geometric opening area of the SPOs and multiplied a bunch of numerical factors between 0 and 1  with that number, where most of these factors depend on energy. For example, the reflectivity of the SPOs can be approximated as one number for each energy assuming some \"average\" reflection angle.\n",
    "\n",
    "A full ray-trace calculation can provide a more detailed prediction of the effective area, in particular in treating geometrical obscuration effects such as \"How many photons hit the support structure of the CAT grating petal?\" or \"How many photons are lost in a chip gap between CCDs?\" However, it is still useful to compare results with the analytic predictions to check the correctness of the ray-trace and to understand where the photons are lost.\n",
    "\n",
    "## Caveats\n",
    "\n",
    "It's surprisingly hard get multiplicative factors that say \"How many photons are lost at this element\" from the results of the ray-trace simulations. MARXS tracks the survival probability for each photon and thus photons carry a different weight. So, we can't just say \"$x$ photons out of $N$ photons hit the CAT support structure and are absorbed, thus the multiplication factor is $x/N$\". In the simulation interactions don't happen in the same sequence that an analytical calculation would use, e.g. in the simulation we loop over all gratings and for each grating we find the intersecting photons and then treat those (pick diffraction order, apply grating efficiency, etc.). At the end, we assign a probability=0 for all those photons that did not hit any grating, assuming that all those will be absorbed by the structure of the CAT petal. However, at that point all photons that DO hit a grating already have adjusted probabilities from the grating efficiency etc.. Thus, we can't just naively take the sum of all probabilities before and after to get the fraction that is absorbed by the CAT petal structure.\n",
    "\n",
    "The underlying problem is that in the simulations rays are additive and we can treat each ray on it's own, one after the other. However, when trying to get these multiplicative factors like \"the CAT support petal absorbs x% of the photons\" we need to compare all photons in the list and ensure that all rays are at the same step. Sometimes, that's not really possible. After all, we do a ray-trace to take into account effects that depend on the specific x,y,z location of an interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.table import Table\n",
    "\n",
    "import marxs\n",
    "from marxs.simulator import KeepCol\n",
    "import arcus\n",
    "import arcus.arcus\n",
    "from arcus.arcus import Arcus\n",
    "from arcus.defaults import DefaultSource, DefaultPointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.sankey import Sankey\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detector_miss(photons):\n",
    "    misses = ~np.isfinite(photons['det_x'])\n",
    "    photons['probability'][misses] = 0\n",
    "    return photons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_tables_from_simulations(energy, n_photons=2e4):\n",
    "    mypointing = DefaultPointing()\n",
    "    mysource = DefaultSource(energy=energy)\n",
    "    photons = mysource.generate_photons(n_photons)\n",
    "    photons = mypointing(photons)\n",
    "    \n",
    "    instrum = Arcus()\n",
    "    keepprob = KeepCol('probability')\n",
    "    keepprobspo = KeepCol('probability')\n",
    "    keepprobcat = KeepCol('probability')\n",
    "    keepprob(photons)\n",
    "    instrum.postprocess_steps = [keepprob]\n",
    "    instrum.elements[1].postprocess_steps = [keepprobspo]\n",
    "    instrum.elements[2].postprocess_steps = [keepprobcat]\n",
    "    instrum.elements.append(detector_miss)\n",
    "    photons = instrum(photons)\n",
    "    \n",
    "    return keepprob.data, keepprobspo.data, keepprobcat.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def multiplicativetable(p, pspo, pcat):\n",
    "    '''Be weary of changes in the definition of the Arcus object.\n",
    "    There is a lot of stuff hardcoded here.'''\n",
    "    d = OrderedDict()  # can just be dict in 3.7 which guarantees dict ordering\n",
    "    noSPO = (pspo[8] == 0) & (pspo[7] > 0)\n",
    "    #d['XOU coverage in aperture rectangle'] = sum(pspo[8]) / sum(pspo[7])\n",
    "    d['XOU coverage in aperture rectangle'] = noSPO.sum(dtype=float) / len(noSPO)\n",
    "    for i in [p[1], pspo[7], pspo[8], pspo[9]]:\n",
    "        i[noSPO] = 0\n",
    "    d['SPO Reflectivity'] = sum(pspo[7]) / sum(p[1])\n",
    "    d['SPO Geometry: Ribs and bars'] =  sum(pspo[9]) / sum(pspo[8])\n",
    "    # Should be the multiplication of the two above. \n",
    "    d['SPO total'] = sum(p[2]) / sum(p[1])\n",
    "    assert np.isclose(d['SPO Geometry: Ribs and bars'] * d['SPO Reflectivity'], d['SPO total'])\n",
    "    noCAT = (pcat[5] == 0) & (pcat[4] > 0)\n",
    "    catin = np.array(p[2], copy=True)\n",
    "    catin[noCAT] = 0\n",
    "    d['photons missing CAT grating'] = sum(catin) / sum(p[2])\n",
    "    for i in pcat:\n",
    "        i[noCAT] = 0\n",
    "    d['CAT efficiency (incl. L1)'] = sum(pcat[3]) / sum(catin)\n",
    "    d['CAT L2 support'] =  sum(pcat[4]) / sum(pcat[3])\n",
    "    \n",
    "    d['CAT Debye-Waller Factor'] =  sum(pcat[6]) / sum(pcat[5])\n",
    "    d['CAT petal total'] =  sum(p[3]) / sum(p[2])\n",
    "    assert np.isclose(d['CAT petal total'], \n",
    "                      d['CAT Debye-Waller Factor'] * d['photons missing CAT grating'] * \n",
    "                      d['CAT L2 support'] * d['CAT efficiency (incl. L1)'])\n",
    "    d['Filter and CCD QE'] = sum(p[4]) / sum(p[3])\n",
    "    d['Boom'] = sum(p[5]) / sum(p[4])\n",
    "    d['Photons missing CCD'] = sum(p[-1]) / sum(p[6])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tab025 = multiplicativetable(*get_probability_tables_from_simulations(.25))\n",
    "tab05 = multiplicativetable(*get_probability_tables_from_simulations(.5))\n",
    "tab10 = multiplicativetable(*get_probability_tables_from_simulations(1.0))\n",
    "tab25 = multiplicativetable(*get_probability_tables_from_simulations(2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perffactors = Table([list(tab05.keys()), list(tab025.values()), list(tab05.values()),\n",
    "                     list(tab10.values()), list(tab25.values())], \n",
    "                    names=['Factor', '0.25 keV', '0.5 keV', '1.0 keV', '2.5 keV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the caveats given above, here is a table of multiplicative factors that shows which fraction of the total photon flux is lost in which step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in perffactors.colnames[1:]:\n",
    "    perffactors[col].format='4.2f'\n",
    "perffactors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, note that not all factors can be compared 1:1 to the analytic estimate. Notice that the Debye-Waller factors for the grating efficiency are much closer to 1 than you might expect. That's because this table includes 0 order photons. For e.g. 2.5 keV most photons end up in 0th order where the Debye-Waller factor is 1. Since we don't know at the beginning which photons go into which order it's not easy to sort out zeroth order photons.\n",
    "\n",
    "It can be done (contact me if you have a significant need), but is outside of the scope of this document right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For plotting porposes, I know multiply the factors above together, so I get an additative list of fluxes \n",
    "(not a multiplicative table) again. However, I want to do that in a particular order that differs from the order\n",
    "in which these numbers are derived in the simulation, thus I do not use the probabilities arrays above directly.'''\n",
    "d = tab05\n",
    "base = {'flow factors': [1., d['SPO total'], d['CAT petal total'], d['Filter and CCD QE'], d['Boom'],\n",
    "                         d['Photons missing CCD']],\n",
    "        'labels': ['Input\\nAperture', 'SPO', 'CAT petal', 'Filters\\nand QE', 'boom', 'CCD misses', 'detected'],\n",
    "        'orientations': [0, 1, 1, 1, 1, 1, 0],\n",
    "}\n",
    "spo = {'flow factors': [d['SPO Geometry: Ribs and bars'], d['SPO Reflectivity']],\n",
    "      'labels': [None, 'Ribs and bars', 'Reflectivity'],\n",
    "      'orientations': [-1, 1, 1],\n",
    "      'scale': 1}\n",
    "cat = {'flow factors': [d['photons missing CAT grating'], d['CAT efficiency (incl. L1)'],\n",
    "                       d['CAT L2 support'], d['CAT Debye-Waller Factor']],\n",
    "      'labels': [None, 'CAT petal\\nstructure', 'efficiency\\nand L1', 'L2', 'Debye-\\nWaller'],\n",
    "      'orientations': [-1, 1, 1, 1, 1],\n",
    "      'scale': d['SPO total']}\n",
    "\n",
    "for d in [base]:\n",
    "    d['flow'] = np.hstack([[1], np.diff(np.cumprod(d['flow factors'])), [-np.prod(d['flow factors'])]])\n",
    "    \n",
    "for d in [spo, cat]:\n",
    "    d['flow'] = d['scale'] * np.hstack([1. - np.prod(d['flow factors']), \n",
    "                           - (1 - np.array(d['flow factors'])) * \n",
    "                           np.cumprod(np.hstack([1, d['flow factors'][:-1]]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_sankey_photons_losses(base, spo, cat, title=''):\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    ax = fig.add_subplot(1, 1, 1, xticks=[], yticks=[],\n",
    "                         title=\"Flow Diagram of a Widget\")\n",
    "    sankey = Sankey(ax=ax, scale=1,# offset=0.2, \n",
    "                    format='%.3f', unit='')\n",
    "    sankey.add(flows=base['flow'],\n",
    "               labels=base['labels'],\n",
    "               orientations=base['orientations'],\n",
    "               pathlengths=[.25, 1., 0.25, 0.25, 0.25, 0.6, 0.25],\n",
    "               #patchlabel=\"Widget\\nA\"\n",
    "              )\n",
    "    sankey.add(flows=spo['flow'],\n",
    "               orientations=spo['orientations'],\n",
    "               labels=spo['labels'],\n",
    "                prior=0,\n",
    "              connect=(1, 0),\n",
    "              label='SPOs',\n",
    "            )\n",
    "    sankey.add(flows=cat['flow'],\n",
    "           orientations=cat['orientations'],\n",
    "           labels=cat['labels'],\n",
    "            prior=0,\n",
    "          connect=(2, 0),\n",
    "          label='CAT')\n",
    "    diagrams = sankey.finish()\n",
    "    diagrams[0].texts[-1].set_color('r')\n",
    "    diagrams[0].text.set_fontweight('bold')\n",
    "    ax.legend()\n",
    "    ax.set_title(title)\n",
    "    return fig, ax, diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a graphic representation of the total photon flow for 0.5 keV (about 24 Ang) photons. Note that the \"detected photons\" in the end again include both dispersed and zero order photons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax, diagrams = plot_sankey_photons_losses(base, spo, cat, '0.5 keV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_codetoggle()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:mayavi3]",
   "language": "python",
   "name": "conda-env-mayavi3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
