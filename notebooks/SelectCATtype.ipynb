{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select gratings for the Arcus mission\n",
    "*At the heart of the Arcus design are the critical angle transmission (CAT) gratings, which diffract the light. The [Space Nanotechnology Laboratory at MIT](http://snl.mit.edu/) is constantly working on improving parameters and fabrication and thus different variants with different thickness, different grating bar width and with or without a coating could be used for Arcus. Depending on the grating parameters, the gratings will have to mounted at different blaze angles for optimal extraction, and that means that the spacing between channels and detectors needs to be different for optimal performance. In this notebook, we look at those optimizations and the expected performance for different grating types, so that the Arcus team has the information it needs to trade-off between capabilities and technical readiness of the gratings.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbtemplate import display_header, get_path\n",
    "display_header('SelectCATtype.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Assumptions for the simulation\n",
    "In an early stage of the Arcus design, there are just too many parameters in flux, to exhaustively run a grid of models over all possible parameter combinations. Thus, I am making some choices which parameters are likely to impact the results in a meaningful way, and which parameters are already set by other constraints, e.g. the SPOs are chosen to have an exact equivalent in Athena for radius and size, but their angular position can be modified to make them fit the Arcus petal. While in principle it is possible to manufacture different SPOs, minor changes (e.g. cutting off the edges by a few mm) will not change the conclusions drawn here and major changes are cost prohibitive for the Arcus mission. I am selecting a set of SPOs and positions and run all simulations with that. Any later changes (e.g. adding or removing SPO rows) will impact all scenarios in the same direction, e.g. removing row 1 reduces the effective area ($A_\\mathrm{eff}$ or sometimes simply labelled as $A$ for short below), but increases the resolving power $R$. While this may change the absolute numbers given for $A$ and $R$ below, a grating type that performs better than another type with SPOs in row 1 will still perform better than the other type without SPOs in row 1.\n",
    "\n",
    "The selection of SPOs is studied separately in a different place.\n",
    "\n",
    "So, the main parameters changing in the simulations below are:\n",
    "\n",
    "- Grating type, in particular:\n",
    "  - depth\n",
    "  - bar width\n",
    "  - coating\n",
    "- blaze angle\n",
    "- distance between optical axes, i.e. distance between zeroths orders on the detector\n",
    "- position of cameras. This ignores CCD gaps and other details, but studies different strategies to determine the area covered by CCDs, assuming a total number of 16 CCDs for Arcus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from astropy import table\n",
    "import astropy.units as u\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "orders = np.arange(-15, 4)\n",
    "outpath = get_path('grid2designtorus')\n",
    "filelist = glob(os.path.join(outpath, '*.fits'))\n",
    "\n",
    "filelist.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_phifolded(p):\n",
    "    p.meta['phi_m'] = np.arcsin(p.meta['D_CHAN'] / 2 / p.meta['CIRCLE_R'])\n",
    "    p.meta['phi_0'] = 2 * p.meta['phi_m']\n",
    "    # make new column \"distance from phi_m\"\n",
    "    p['phi_folded'] = np.abs(p['circ_phi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from arcus analyse_design\n",
    "# Keep here? Put in marxs itself? put in separate file and define there?\n",
    "\n",
    "def angle_covered_by_CCDs(p, n_ccds=8):\n",
    "    return n_ccds * 49.5 / p.meta['CIRCLE_R']\n",
    "\n",
    "\n",
    "def best_ccd_pos_incl0(p, n_ccds=8):\n",
    "    '''One possible function to select the \"optimal\" detector position\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p: photon list\n",
    "        needs to have phi_folded in it\n",
    "    '''\n",
    "    ang8 = angle_covered_by_CCDs(p, n_ccds=n_ccds)\n",
    "    binwidth = angle_covered_by_CCDs(p, n_ccds=0.1)\n",
    "    # Approximate, but good enough for this purpose\n",
    "    # For example, ignore +- 2.5 mm offset between channel\n",
    "    zeropos = np.arcsin((p.meta['D_CHAN'] / 2) / p.meta['CIRCLE_R'])\n",
    "    # Look at region +- 8 CCDS from the zeros order, because we definitely\n",
    "    # want that in the range.\n",
    "    # Don't go +/- 8 CCDs, but a little less, so zeroth order is never\n",
    "    # exactly on the edge of detector\n",
    "    bins = np.arange(\n",
    "        # Don't go below 0 because that's where we fold\n",
    "        max(0, zeropos - (ang8 - binwidth)),\n",
    "        zeropos + (ang8 + binwidth), \n",
    "        binwidth)\n",
    "    hist, bin_edges = np.histogram(p['phi_folded'], weights=p['probability'], bins=bins)\n",
    "    signal = np.cumsum(hist)\n",
    "    signal8 = signal[int(n_ccds / 0.1):] - signal[:-int(n_ccds / 0.1)]\n",
    "    return bins[np.argmax(signal8)]\n",
    "\n",
    "\n",
    "def make_det_scenarios(p):\n",
    "    pdisp = p[p['order'] != 0]\n",
    "    \n",
    "\n",
    "    # Scenario 0: All photons\n",
    "    det_scenarios = [{'phi_start': 0., 'phi_stop': .2,\n",
    "                      'scenario_name': 'all_photons'}]\n",
    "    \n",
    "    # Scenario 1: Maximize highly dispersed photons\n",
    "    phistart = best_ccd_pos_incl0(p[p['circ_phi'] > 0])\n",
    "    det_scenarios.append({'phi_start': phistart,\n",
    "                          'phi_stop': phistart + angle_covered_by_CCDs(p),\n",
    "                          'scenario_name': '8 CCDs: high-res'})\n",
    "    # Scenario 1b: Maximize highly dispersed photons\n",
    "    phistart = best_ccd_pos_incl0(p[p['circ_phi'] > 0], n_ccds=10)\n",
    "    det_scenarios.append({'phi_start': phistart,\n",
    "                          'phi_stop': phistart + angle_covered_by_CCDs(p, n_ccds=10),\n",
    "                          'scenario_name': '10 CCDs: high-res'})\n",
    "    # Scenario 2: Maximize dispersed photons\n",
    "    phistart = best_ccd_pos_incl0(pdisp)\n",
    "    det_scenarios.append({'phi_start': phistart,\n",
    "                          'phi_stop': phistart + angle_covered_by_CCDs(p),\n",
    "                          'scenario_name': '8 CCDs: all'})\n",
    "\n",
    "    # Scenario 3: Maximize dispersed O VII photons\n",
    "    po7 = pdisp[(pdisp['wave'] > 21.6) & (pdisp['wave'] < 28.01)]\n",
    "    phistart = best_ccd_pos_incl0(po7)\n",
    "    det_scenarios.append({'phi_start': phistart,\n",
    "                          'phi_stop': phistart + angle_covered_by_CCDs(p),\n",
    "                          'scenario_name': 'max O VII'})\n",
    "\n",
    "    # Scenario 4: Maximize band 33-40 Ang\n",
    "    #po7 = pdisp[(pdisp['wave'] > 33.7) & (pdisp['wave'] < 40.01)]\n",
    "    #phistart = best_ccd_pos_incl0(po7)\n",
    "    #det_scenarios.append({'phi_start': phistart,\n",
    "    #                      'phi_stop': phistart + angle_covered_by_CCDs(p),\n",
    "    #                      'scenario_name': 'max 33.7-40 Ang'})\n",
    "    return det_scenarios\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marxs.analysis.gratings import (effectivearea_from_photonlist, \n",
    "                                     resolvingpower_from_photonlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_simulation(filename):\n",
    "    evt = table.Table.read(filename)\n",
    "    ind = np.isfinite(evt['circ_phi']) & np.isfinite(evt['order']) & (evt['probability'] > 0)\n",
    "    p = evt[ind]\n",
    "    add_phifolded(p)\n",
    "    p['wave'] = p['energy'].to(u.Angstrom, equivalencies=u.spectral())\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "\n",
    "orders = np.arange(-15, 4)\n",
    "results = []\n",
    "\n",
    "    \n",
    "\n",
    "for f in filelist:\n",
    "    p = load_simulation(f)\n",
    "    zeropos = np.median(p[p['order'] == 0]['circ_phi'])\n",
    "    \n",
    "    \n",
    "    for s in make_det_scenarios(p):\n",
    "        p_scenario = p[(p['phi_folded'] > s['phi_start']) & (p['phi_folded'] < s['phi_stop'])]\n",
    "        p_wave = p_scenario['wave', 'probability', 'circ_phi', 'order'].group_by('wave')\n",
    "        for wave, group in zip(p_wave.groups.keys, p_wave.groups):\n",
    "            wave = wave[0]\n",
    "            aeff = effectivearea_from_photonlist(group, orders, group.meta['N_PHOT'], group.meta['A_GEOM'] * u.cm**2)\n",
    "            \n",
    "            # see https://github.com/astropy/astropy/issues/13281\n",
    "            # Since we know the warning is a bug, let's ignore it.\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "                res, pos, std = resolvingpower_from_photonlist(group, orders, col='circ_phi', zeropos=zeropos)\n",
    "            \n",
    "            results.append({'filename': f,\n",
    "                            'scenario': s['scenario_name'],\n",
    "                            'phirange': (s['phi_start'], s['phi_stop']),\n",
    "                            'wave': wave,\n",
    "                            'aeff': aeff,\n",
    "                            'res': res} |\n",
    "                            {k : p.meta[k] for k in ['TORUS_R','CIRCLE_R','MAX_F','BLAZE','D_CHAN', 'GRATTYPE']},\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = table.Table(rows=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How are the photons distributed on the detector?\n",
    "\n",
    "In the simulations, I used a detector that covered the entire Rowland circle. That allows us to study the best position for the CCDs after the fact without rerunning time-consuming Monte-Carlo simulations.\n",
    "\n",
    "Here, I study five different detector placement algorithms:\n",
    "\n",
    "1) all_photons: Detector is a larger number of CCDs, such that every photons gets counted\n",
    "2) 8 CCDs: 8 CCDs per camera, for a total of 16 CCDs. The location of each camera (each with 8 CCDs) is limited to locations that guarantee that the zero order is detected. Under that condition, it is then moved around to optimize the total number of dispersed orders with relatively high resolving power (i.e. those $\\phi > 0$ in the plots below).\n",
    "3) Same as (2), but with 10 CCDs per camera.\n",
    "4) Same as (2), but using all dispersed photons, also those with low $R$ relatively close to the optical axis (order +/-1, +/-2, etc.). This potentially increases $A$ and the cost of loosing some highly-dispersed photons and thus reduced $R$.\n",
    "5) max O VII: like 8 CCDs, but optimizing just for the number of photons in a band close to the O VII triplet\n",
    "\n",
    "I can easily add more strategies and re-run the plots below for example to optimize for different energy bands, but these algorithms cover a range of probabilities that are reasonable for Arcus.\n",
    "\n",
    "The input spectrum is list of discrete energies over the Arcus bandpass; the main purpose here is not to simulate a real spectrum, but to cover the bandpass well enough to calculate $R$ and $A$ with a sufficient number of counts. That means that \"maximizing the number of counts\" might result in different best detector position depending on the spectrum of the astrophysical object observed. However, most of the dispersed photons fall into the blaze peak, so that this is not a strong dependence and thus is sufficient for this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the last file that's still in memory.\n",
    "# Just to check that everything is normal, the format looks OK etc.\n",
    "def plot_phi_hist(p, orders_to_plot = [3, 2, 1, 0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10, -11]):\n",
    "    fig, ax = plt.subplots(nrows=2, sharex=True, height_ratios=[1, 4],\n",
    "                           gridspec_kw={'hspace': 0})\n",
    "\n",
    "    for i, s in enumerate(make_det_scenarios(p)):\n",
    "        out = ax[0].plot([s['phi_start'], s['phi_stop']], [i, i], label=s['scenario_name'], lw=8)\n",
    "        ax[0].plot([-s['phi_start'], -s['phi_stop']], [i, i], label='_no_legend_',\n",
    "                   color=out[0].get_color(), lw=8)\n",
    "        ax[0].text(.21, i, s['scenario_name'])\n",
    "    #ax[0].legend()\n",
    "    ax[0].set_axis_off()\n",
    "    \n",
    "    cmap = plt.get_cmap('nipy_spectral')\n",
    "    color = cmap(np.linspace(0, 1, max(np.abs(orders_to_plot)) + 1))\n",
    "    colors = [color[abs(i)] for i in orders_to_plot]\n",
    "\n",
    "    out = ax[1].hist([p['circ_phi'][p['order']==i] for i in orders_to_plot], \n",
    "                    color=colors,\n",
    "                    bins=100, stacked=True, label=orders_to_plot)\n",
    "    ax[1].legend()\n",
    "    ax[1].set_xlabel('angle on Rowland circle (rad)')\n",
    "    out = ax[1].set_ylabel('counts / bin')\n",
    "    return fig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.meta['BLAZE'], p.meta['D_CHAN'], p.meta['GRATTYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_phi_hist(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For one example, this plot shows how photons are distributed on the Rowland circle (blaze angle 2.2 deg, DCHAN=750 mm, grating type 5.7-50-Si). The input spectrum is list of discrete energies over the Arcus bandpass; the main purpose here is not to simulate a real spectrum, but to cover the bandpass well enough to calculate $R$ and $A$ with a sufficient number of counts.\n",
    "\n",
    "Positive orders are to the left of the zeroth order, negative orders on the right. The colored bars on the top of the plot indicate which areas are covered by CCDs for different CCD placement scenarios. Arcus has two cameras with a gap in between, thus there are two strips symmetric around $\\phi=0$.\n",
    "\n",
    "The zeroth order is found around -0.06 rad, because the circle is centered on the geometrical center of the instrument in the middle between the optical axis of the separate channels. In the case of the single channel simulated here, the zeroth order is to the left of that center by about the same distance as the blaze peak - the location where the brightest diffracted orders are seen. The simulation is run for a few discrete wavelengths; since the diffraction angle depends on wavelength e.g. order -4 is found at different locations. \n",
    "\n",
    "In this example, the CCD are all in a very similar location, but that might be different in other cases, an example of which is shown in the plot below. In both cases, it is clear that using a larger number of CCDs will capture more of the wings of the blaze peak and thus provide more effective area. While most of the photons are in the blaze peak, the difference can matter a lot more for very specific wavelength."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tab[(tab['D_CHAN'] == 700.) & (tab['GRATTYPE'] == '4-70-Si') & (tab['BLAZE'] == 1.8)]['filename'][0]\n",
    "fig = plot_phi_hist(load_simulation(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example (blaze angle 1.8 deg, DCHAN=7500 mm, grating type 4-70-Si) shows how different strategies to place the detectors can impact the effective area: There is a relatively large number of photons in low orders close to the zeroth order and the \"8 CCDs: all\" scenario shifts the CCDs to catch those at the cost of missing the far end of the blaze peak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab['0 order covered'] = tab['aeff'].data[:, orders==0].flatten() > 0\n",
    "\n",
    "### average by order number\n",
    "high_res = orders < -3\n",
    "\n",
    "grating_aeff = tab['aeff'].data[:, high_res]\n",
    "tab['aeff'].data[:, orders < -2]\n",
    "tab['Aeff (high res)'] = grating_aeff.sum(axis=1)\n",
    "tab['R (high res)'] = np.ma.average(np.ma.masked_invalid(tab['res'].data[:, high_res]), \n",
    "              weights=grating_aeff / grating_aeff.sum(axis=1)[:, None],\n",
    "              axis=1)\n",
    "\n",
    "### by R > 1000\n",
    "\n",
    "highres = tab['res'].data > 1000\n",
    "res_arr = np.ma.masked_array(tab['res'].data, mask=~highres)\n",
    "aeff_arr = np.ma.masked_array(tab['aeff'].data, mask=~highres)\n",
    "        \n",
    "tab['A (R > 1000)'] = aeff_arr.sum(axis=1)\n",
    "tab['R (R > 1000)'] = np.ma.average(res_arr, \n",
    "              weights=aeff_arr / aeff_arr.sum(axis=1)[:, None],\n",
    "              axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion from energy to wave leaves values like 14.9999999999999997\n",
    "# Let's fix that.\n",
    "tab['wave'] = np.around(tab['wave'], decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "All simulations are *for one channel only*, so $A_\\mathrm{eff}$ of all four channels together will be four times larger, except at the edges (due to channels being displaced by a few mm with respect to each other) or when it hits a chip gap.\n",
    "\n",
    "The simulations are run for a grid over several parameters and we have multiple ways to slice and dice the results. We can, for example, look at one particular grating type and show how the efficiency changes with blaze angle and torus parameters at a particular wavelength. Or, we could look at how the efficiency for a given blaze angle depends on the wavelength (the classic effective area curve). Below, I'm going to explore a few of those options, but this is not a complete set of all possibilities.\n",
    "\n",
    "Our dataset has the following main parameters\n",
    "\n",
    "- Grating type (coated, uncoated, depth, bar dimensions)\n",
    "- d_BF: Distance between the channels\n",
    "- R: Radius of Rowland circle\n",
    "- wavelength\n",
    "- Detector placement: I've run different scenarios, optimizing the detector position to catch as much dispersed signal overall, as much signal in O VII as possible, optimizing the signal at the long wavelength range (33.7 - 40 Ang), or using a detector that is large enough to catch each and every photon, which might require more than 16 CCDs in total.\n",
    "\n",
    "And, reminder: There are other parameters that I have left unchanged over all simulations, namely the set-up of the SPOs. I'm taken a realistic design, but not necessarily the design that Arcus will end up with, e.g. I'm using row 1 from Athena here; I have not changed the coating of the SPOs, etc.\n",
    "\n",
    "We also need to handle the issue that we'll see different orders for more wavelength. Those orders will have different R and Aeff, yet for plots that compare other parameters we need to simplify and not plot Aeff and $R$ for each order separately. So, I'm making an effective-area weighted average of the $R$ values for all the high-resolution orders. It is not a good idea to simply average over all orders, because in some cases, we see order 0, -1, and -8, where $R$ in -8 is orders of magnitude better than in orders -1 and 0. However, what makes an order \"high resolution\" such that it should be included in this average? For long wavelength ($ > 15$ Ang or so), typically \"high-resolution\" means higher orders or \"orders with $R>1000$\" so that's what I'm using for the plots below. However, that gives some odd results at some wavelengths, e.g. if we have two orders that contribute equal effective area with $R=1010,1200$ and a small change in parameters make the resolution drop a little, we might end up with $R=950, 1150$. Now, the first of those orders is no longer considered \"high-resolution\" and not part of the average, so the average $R$ apparently jumps from $\\frac{1010 + 1200}{2}=1105$ to $1150$. Similarly, a small change might make one high-resolution order drop off the detector, causing a sudden jump in $R$ and $A_\\mathrm{eff}$.\n",
    "\n",
    "I will first show a few cuts through this simulated data to explain how to read it and then provide an interactive display allowing you to explore all the scenarios I simulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas dataframes can't have multi-D columns, but they have nifty build-in plotting\n",
    "# So, make a dataframe for those columns that are not multi-D\n",
    "df = tab.copy()\n",
    "df['phistart'] = tab['phirange'].data[:, 0]\n",
    "df['phistop'] = tab['phirange'].data[:, 1]\n",
    "df.remove_columns(['aeff', 'res','phirange'])\n",
    "df = df.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different detector placement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = sns.relplot(\n",
    "    data=df[(df.D_CHAN == 700.) & (df.GRATTYPE == '4-70-Si')],\n",
    "    x='wave', y='A (R > 1000)', col=\"GRATTYPE\", hue='BLAZE',\n",
    "    kind='line', errorbar=lambda x:(x.min(), x.max()), linewidth=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effective area depending on wavelength for a 4-70-Si at D_CHAN == 700 mm for different blaze angle. For each blaze angle, the shaded area marks the region from the CCD placement scenario that gives the best value for $A$ (the \"all_photons\" scenario with > 30 CCDs) to the one the gives the least area (one of the scenarios with 8 CCDs per camera).\n",
    "\n",
    "The width of the strips shows that we are loosing up to 40% of the effective area when the blaze peak is not covered well with CCDs.\n",
    "\n",
    "In the following, we will concentrate on the \"8 CCDs (high-res)\" scenario that optimized coverage of the blaze peak with 8 CCDs per camera, but we need to keep in mind that, depending on the configuration we choose in the end, we might add significant effective area by having more CCDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The blaze angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = sns.relplot(\n",
    "    data=df[(df.wave == 20.0) & (df.GRATTYPE == \"4-60-Si\")],\n",
    "    x='R (R > 1000)', y='A (R > 1000)', hue=\"BLAZE\", col=\"scenario\", size='D_CHAN',\n",
    "    col_wrap=4, height=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R and Aeff at 20 Ang for different detector placements. When all photons are detected (left), $R$ simply increases with the blaze angle. The larger the blaze angle, the further out the blaze peak; in other words, photons get diffracted into higher orders. Because the dispersed photons are further away from the optical axis in higher orders, $R$ increases approximately linearly with the blaze angle (in degrees). The effective area $A$ increases at first, until it hits an optimum around 1.6 deg and then increases again. D_CHAN is the physical distance between channels. If it is too small, the SPOs of different channels overlap, if it's too large the channels won't fit within the front assembly. The number given is measured in mm center-to-center for SPO petals, which is the distance of the two optical axis. For the \"all_photons\" scenario, D_CHAN has only very small influence on $R$ and $A$, but if the number of CCDs is limited, photons may fall of the detector. For small D_CHAN, the detectors need to be close together to make sure that all zeroth orders land on a CCD. At large blaze angles (e.g. $>1.9$ deg), the blaze peak is so far out, that a camera cannot see the major important dispersed orders any longer and thus $A$ is much lower for small D_CHAN values as shown e.g. by the black points in the \"max O VII\" scneario.)\n",
    "Sometimes, this also lowers $R$, which is shown averaged over the visible orders, if one of the highest orders drops of the chip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(\n",
    "    data=df[(df.wave == 20.0) & (df.D_CHAN == 650.)],\n",
    "    x='R (R > 1000)', y='A (R > 1000)', hue=\"BLAZE\", col=\"GRATTYPE\", size='scenario',\n",
    "    col_wrap=4, height=3, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again choosing 20 Ang as an example and selecting a larger D_CHAN = 700 mm, this plot shows how the blaze angle changes the effective area. Deeper gratings (those starting with \"5.7\" in the name) peak at lower blaze angles and they drop-off more to larger blaze angles; for example the \"5.7-40-Si-6-Ni\", a 5.7 $\\mu$m deep grating with 30 nm wide Si bars, coated with 6 nm of Pt) peaks at 1.2 deg blaze angle or even below that (1.2 deg is the smallest angle in this set of simulations), while the 4 $\\mu$m deep gratings peak at 1.6 deg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which grating is the best?\n",
    "There are a fer parameters we can choose (within limits): The blaze angle and the channel spacing. So, for each grating type, we need to select the \"best\" blaze and D_CHAN and then see what we get for Aeff and R. However, as the plots above showed, choosing the \"best\" combination brings in some trade-off between $R$ and $A$. We can go to a higher blaze angle to increase $R$ but sacrifice some effective area if that blaze angle is larger than the optimal solution.\n",
    "\n",
    "### Step 1: Select the blaze angle\n",
    "Fortunately, $R$ for the high-res orders depends essentially only on the blaze angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hue_order = [\n",
    " '4-70-Si',\n",
    " '4-60-Si',\n",
    " '4-60-Si-6-Pt',\n",
    " '4-60-Si-6-Ni',\n",
    " '4-40-Si-6-Pt',\n",
    " '5.0-50-Si',\n",
    " '5.7-50-Si',\n",
    " '5.7-40-Si',\n",
    " '5.7-40-Si-6-Pt',\n",
    " '5.7-40-Si-6-Ni',\n",
    " '5.7-28-Si-6-Pt',\n",
    "]\n",
    "hue_kws = {\n",
    "    'linewidth': [{'4': 1, '5.0': 1.7, '5.7': 3}[h.split('-')[0]] for h in hue_order],\n",
    "    'linestyle': ['--' if '-6-' in h else 'solid' for h in hue_order]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    data=df[(df.scenario == \"8 CCDs: high-res\") & (df.D_CHAN == 650.)],\n",
    "    col=\"BLAZE\", hue='GRATTYPE', hue_order=hue_order, hue_kws=hue_kws,\n",
    "    height=3\n",
    "    )\n",
    "out = g.map_dataframe(sns.lineplot, x='wave', y='R (R > 1000)')\n",
    "out = g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R$ for different blaze angles. $R$ is shown as a weighted average over all orders with $R>1000$, i.e. all the photons in the blaze peak. A remarkable property of CAT gratings is that $R$ is essentially constant with wavelength; the fundamental reason for this is that all photons are diffracted into the blaze peak. They end up in different diffraction orders, but at very similar detector locations and thus have the same $R$. Small wiggles stem from numerics of a Monte Carlo simulation and from the fact that sometimes one of the lesser contributing (but not negligible) order is not covered by the CCDs.\n",
    "\n",
    "There is some scatter at very low wavelength because the number of photons that get dispersed into the blaze peak is lower. In the next plot, we will show the value for $R$ at 25 Ang to avoid those problems and get an $R$ that is representative for each blaze angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = sns.boxplot(data=df[(df.scenario == \"8 CCDs: high-res\") & (df.wave==25.)],\n",
    "                x='BLAZE', y='R (R > 1000)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resolving power vs. blaze angle (in deg). The box includes simulations for different D_CHAN and different gratings types. The boxes show the quartiles of the distribution, whiskers the full distribution, black markers any outliers. \n",
    "\n",
    "We see that the distributions are very narrow and that $R$ depends linearly on the blaze angle. **Given this plot, we can pick out the minimum $R$ that is required by the science and thus the minimum blaze angle.**\n",
    "\n",
    "For example, if we want to achieve a $R> 3500$, then we need to get to a blaze $>1.8 deg$ with some margin, since the simulation above do not yet apply an alignment budget."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Select the grating type\n",
    "\n",
    "Knowing the minimal blaze angle, we can now look for the best grating to use, taking into account the effective area and the TRL of the grating.\n",
    "\n",
    "In general, smaller blaze angles give better effective area $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(\n",
    "    data=df[(df.scenario == \"8 CCDs: high-res\") & (df.D_CHAN == 650.)],\n",
    "    col=\"BLAZE\", hue='GRATTYPE', hue_order=hue_order, hue_kws=hue_kws,\n",
    "    height=3, col_wrap=3\n",
    "    )\n",
    "out = g.map_dataframe(sns.lineplot, x='wave', y='A (R > 1000)')\n",
    "out = g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effective area curves for different gratings and different blaze angles. Pure Si gratings are shown with solid lines, coated gratings with dotted lines. The deeper the grating the ticker the line.\n",
    "\n",
    "Following the example from the last plot for $R> 3500$, we are looking at blaze angles 2.0 or 2.2 degrees. Since the effective area drops for larger blazes, we select 2.0 degrees. At that wavelength, we see that coated gratings are significantly better at short wavelength, but in the prime Arcus bandpass, the pure Si gratings perform better. The deeper the grating, and the thinner the bars, the better the effective area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Caveats\n",
    "The simulations above concentrate on a few parameters that are relevant to choose the best grating. While the number for $A$ is reasonable, there are a number of effects not included, because they affect each grating in the same way. When they are taken into account, the relative ordering of gratings stays the same, but the absolute value of $A$ might change.\n",
    "\n",
    "- This is for one channel only.\n",
    "- L1 cross-dispersion is not treated - in practice not all cross-dispersed photons can be used, reducing $A$ by a few percent.\n",
    "- L1 and L2 absorption are the same for all simulated gratings If L1 and L2 become thinner (or the duty cycle larger) the effective area will increase because (a) less light is blocked and (b) there is less cross-dispersion.\n",
    "- choice of SPOs: These simulations are run with one probably optimistic set of SPOs. If we drop SPOs from that set, the effective area will shrink.\n",
    "- Chip gaps will reduce $A$ for some wavelengths.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('Arcus')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19d5601b7109f36b9de8e56622ce9ffae5a9d961730b52581061a43994a758db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
