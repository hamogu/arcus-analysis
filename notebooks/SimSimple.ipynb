{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations with a simplified response matrix\n",
    "\n",
    "*I present a simplified response for Arcus simulations, consisting of just four files: ARF/RMF for zero order and ARF/RMF summed over all dispersed orders. For simplicity, I sum the effective area of the relevant dispersed spectra and average the resolving power. This ignores problems with order-sorting, which will be relevant for detecting weak absorption lines. Also, in reality, different orders will have different spectral resolution.* **If order-sorting (continuum sources!) or very high spectral resolution (> 3000) is important, simulations should be done for individual orders, not with this merged response.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbtemplate import display_header, get_path\n",
    "display_header('SimSimple.ipynb', status='Arcus 2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:orange;font-weight:bold\">\n",
    "If you are reading a static version of this document (e.g. as a readme distributed with arf/rmf files), check <a href=\"https://space.mit.edu/home/guenther/ARCUS/SimSimple.html\">https://space.mit.edu/home/guenther/ARCUS/SimSimple.html</a> for updates.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The need for a simple simulations approach\n",
    "Arcus has four different channels, and in each channel we detect > 15 dispsered orders. Since Arcus has two cameras, some of the signal is detected quite close to the zero order and has resolving powers $R$ of just a few hundred, while most of the signal is dispersed to much larger distances, where we expect to reach resolving powers > 3500. For each order, $R$ changes with wavelength, and at any given wavelength, we will detect signal in different orders simultaneously at different values of $R$.\n",
    "\n",
    "To make matters more complicated, order-sorting is not perfect and significant order confusion will appear, i.e. in order -5, we will also see some signal from order -4 and -6, which is dispersed in a different way. Thus, the full ARF/RMF set to simulate all this needs > 180 ARF/RMF pairs (4 channels x 15 orders x 3, where the last factor acounts for the extracted order and the interloper orders from insufficient order sorting). This clearly is too complicated for most simulations. Thus, I provide here a simplified set of ARF/RMF that averages over all grating orders.\n",
    "\n",
    "## Caveats\n",
    "By averaging, we loose some information and brush over some important science implications. However, I expect that the ARF and RMF files presented here will be sufficient to study the majority of science cases.\n",
    "\n",
    "### Reduced peak resolving power, but overestimate of effective area at intermediate resolving power\n",
    "I add up effective areas and average $R$ over all relevant orders (using the effective area in each order to weight the  average). Before averaging, some orders provide a better $R$, sometimes significantly so. For example, at 20 Å, Arcus will see several orders with different $R$. For a science investigation that needs to separate two close emission lines, the *average* resolving power might be insufficient, but it maybe could still be done by using only the order that provides the best $R$ (at the cost of a lower effective area). Such a science case needs to be simulated using \"per order\" arf and rmf files. On the other hand, not all orders have the average $R$. A science investigation that requires exactly $R = R_\\mathrm{average}$ will find that in practice some orders have higher and some orders have lower $R$. If the orders with lower $R$ are insufficient and only some orders can be used, then the exposure time needs to be longer to account for that.\n",
    "\n",
    "### Order confusion\n",
    "Dispersed Arcus orders will land at the same physical location of the detector and orders need to be sorted using the CCD energy resolution. Since orders are closely spaced in energy space, this order sorting is not easy. Either significant effective area is lost by extracting only very narrow regions in energy space (up to factors of a few in the most extreme scenarios!) or a significant fraction (20% for some scenarios with broad order-sorting regions) of the photons are sorted into the wrong order. This is not as much a problem for emission line sources since comparison of different orders can help to identify lines seen in the wrong order, but for sources with absorption lines on a strong continuum, this will effectively act as an extra background, and increases in Poisson noise in the continuum measurement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is included in the ARF and RMF?\n",
    "\n",
    "ARF and RMF are calculated based on MARXS ray-tracing. Details of this ray-tracing are described at [Moritz home page](https://space.mit.edu/home/guenther/ARCUS/index.html). In short, the procedure is as follows: A ray-trace simulation is run for a monoenergetic point source at the nominal aimpoint position for a large number of photons. These photons are then propagated through a simple mirror model and the gratings to the CCDs. The ratio of the number of input photons vs. the number of detected photons gives the ARF. The spatial distribution can be fitted and gives the input to the RMF. Simulations are run using a large number of photons on a relatively coarse grid (1 Å). That grid is sufficient to determine the factors that depend mostly on the geometry (e.g. the shadows cast by the grating support structure). The spot sizes are fitted with a combination of Gaussian and Lorentzian components and stored in LSFPARM files in exactly the same format that the Chandra CALDB uses for this purpose. When generating the RMF on an arbitary energy grid, these factors are interpolated. For the ARF, the \"geometric\" factors from the ray-trace are interpolated on the new energy grid, the position of the CCD edges in wavelength space is calculated analytically, and then multiplied by the factors that depend only on the photon energy (such as the QE of the CCDs). The latter factors are given at a higher energy resolution. Thus, the resulting ARF will properly describe sharp features such as edges in the CCD response, but not have the same random noise that would happen if the ARF and RMF files were constructed from Monte-Carlo simulations are that run independently for every wavelength bin. (Also, this approach requires several orders of magnitude less computing time.)\n",
    "\n",
    "The follwing effects are included in ARF and RMF:\n",
    "\n",
    "- Sum of effective area for order 2, 1, and -1 to -11 (0 order is treated separately)\n",
    "- Arcus 2021 SPO size and location \n",
    "- SPO coating\n",
    "- SPO in-plane and off-plane Gaussian scatter\n",
    "- 4 $\\mu$m deep CAT gratings with nominal 1.8 deg blaze (CAT locations from Ed Hertz) \n",
    "- 4 channels, offset such that chip gaps never overlap (channel placement from optics telecon in Dec 2020),\n",
    "- newest filter and CCD QE curves by Eric Miller \n",
    "- contamination estimate by Meg \n",
    "- all geometric shadowing (from CAT grating mount under SPO) \n",
    "- CAT grating L1 and L2 blockage \n",
    "- L1 cross-dispersion and L2 dispersion \n",
    "- nominal residual pointing jitter (=uncertainty in pointing knowlege), but no jitter beyond that (i.e. constant   aspect solution, so chip-gaps are not filled in by jitter)\n",
    "- mechanical misalignment according to Arcus alignment budget\n",
    "\n",
    "\n",
    "## What it not included?\n",
    "\n",
    "- order sorting and losses due to OSIP filtering\n",
    "- choice of spatial extraction regions. Currently, I'm using all photons\n",
    " that are not cross-dispersed, but that is at the same time \n",
    "too restrictive (for low background, one can get more signal by\n",
    "including a wider region), and not ambitious enough ($R$ could be enhanced\n",
    "by extracting a narrower region).\n",
    "\n",
    "- chip edges are included, but treatment of the exact edge is not fully\n",
    "correct (should not be this sharp due to finite RMF)\n",
    "\n",
    "- cross-channel contamination\n",
    "\n",
    "- off-axis / extended sources\n",
    "- CCD details like read-out streaks, hot pixels etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do ARF and RMF look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.units as u\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sherpa.astro import ui\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve labelling of log scales\n",
    "mpl.rcParams['axes.formatter.min_exponent'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arfrmfpath = '../../arfrmf/merged/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '2021-03-30'  # Date in filename\n",
    "arf0 = ui.unpack_arf(arfrmfpath + f'{date}_chan_all_0.arf')\n",
    "arfd = ui.unpack_arf(arfrmfpath + f'{date}_chan_all_dispersed.arf')\n",
    "rmf0 = ui.unpack_rmf(arfrmfpath + f'{date}_chan_all_0.rmf')\n",
    "rmfd = ui.unpack_rmf(arfrmfpath + f'{date}_chan_all_dispersed.rmf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(10, 4))\n",
    "ax[0].semilogx(arf0.x, arf0.y, label='order 0')\n",
    "ax[0].semilogx(arfd.x, arfd.y, label='dispersed')\n",
    "ax[0].set_xlabel(arf0.get_xlabel())\n",
    "ax[0].set_ylabel('$A_\\mathrm{eff}$ (' + arf0.get_ylabel() + ')')\n",
    "ax[0].get_xaxis().set_minor_formatter(mpl.ticker.LogFormatterMathtext(labelOnlyBase=False,\n",
    "                                                                   minor_thresholds=(2, .5)))\n",
    "ax[0].tick_params(axis='x', labelsize=mpl.rcParams['xtick.labelsize'], which='both')\n",
    "out = ax[0].legend()\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot((arf0.x * u.keV).to(u.Angstrom, equivalencies=u.spectral()), arf0.y, label='order 0')\n",
    "ax[1].plot((arfd.x * u.keV).to(u.Angstrom, equivalencies=u.spectral()), arfd.y, label='dispersed')\n",
    "ax[1].set_xlabel('wavelength ($\\AA$)')\n",
    "out = ax[1].set_ylabel('$A_\\mathrm{eff}$ (' + arf0.get_ylabel() + ')')\n",
    "out = ax[1].grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure shows the effective area for the dispersed signal and the direct light (0 order) over energy (left) and wavelength (right). The 0 order has significant throughput at high energies. At low energies, the dispersed order dominates. Note that the wiggles as low energies for the dispersed order are not noise, but due to some order in some channel falling in a chip gap. However, channels are arranged such that the chip gaps occur at different wavelength for each channel. That way, none of the chip gaps is very deep in the summed effective area curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next plots show five representative line spread functions for the 0 order and the dispersed spectrum and list some properties of the RMF like the energy range covered and the number of bins. Note that these plots use a logaritmic scale in energy, which makes the RMF look narrower at higher energies, although the FWHM actually increses with energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmf0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure shows five exemplary line spread functions for the averaged RMF of the dispersed orders. Note that the y axis is logarithmic. The line spread function is narrow for low energies (large wavelength) that are seen in the higher orders and wider for higher energies, that are only see in order 1 or 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the spectral resolution\n",
    "As a simple illustration of the spectral resolution, I fake a single, very narrow emission line. Then, I can check $R=\\frac{\\lambda}{\\Delta\\lambda}$ where we take the FWHM of the line as $\\Delta\\lambda$. For this and all following simulations, I'm using [Sherpa](https://cxc.cfa.harvard.edu/sherpa/), which is distrubuted with [CIAO](https://cxc.cfa.harvard.edu/ciao/). Use the \"toggle on/of code\" button on the top of this page ([interactive version](https://space.mit.edu/home/guenther/ARCUS/SimSimple.html)) to see the commands. Of course, this is just an example. The ARF and RMF files are OGIP compliant and any other X-ray modelling package (XSPEC, ISIS, SPEX, ...) should work similarly.\n",
    "\n",
    "#### Dispersed spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.set_source('fake_gauss', ui.gauss1d.g1)\n",
    "g1.pos = 20.0\n",
    "g1.fwhm = 0.0001\n",
    "g1.ampl = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set analysis only works if a dataset has been loaded already, so we make one first\n",
    "# and then overwrite it again after calling \"set_analysis\"\n",
    "ui.fake_pha('fake_gauss', arfd, rmfd, 5)\n",
    "ui.set_analysis(\"wave\")\n",
    "ui.fake_pha('fake_gauss', arfd, rmfd, 1e4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.ignore(None, None)\n",
    "ui.notice(g1.pos.val-0.01, g1.pos.val+0.01)\n",
    "#ui.ignore(None, g1.pos.val-0.01)\n",
    "#ui.ignore(g1.pos.val-0.01, None)\n",
    "ui.plot_fit('fake_gauss')\n",
    "ax = plt.gca()\n",
    "#out = ax.set_xlim(g1.pos.val-0.01, g1.pos.val+0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows a faked line at 20 Å. Orange is the input model (in the binning used in the ARF and RMF) and blue are simulated photons counts, where I have simulated so many photons, that the Poisson noise is negligible. I am now taking the x (wavelength) and y (count rate) numbers in the plot above and fit a Gaussian line to it without folding it through the RMF. That way, I can measure the observed line profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = ui.get_data_plot('fake_gauss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sherpa.models import NormGauss1D\n",
    "from sherpa import stats\n",
    "from sherpa import optmethods\n",
    "from sherpa.data import Data1D\n",
    "from sherpa.fit import Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Data1D('verify_R', pl.x, pl.y)\n",
    "howwide = NormGauss1D('verify_R')\n",
    "# Start close to final values to speed up convergence\n",
    "howwide.fwhm = 0.01\n",
    "howwide.pos = g1.pos.val\n",
    "howwide.ampl = np.max(pl.y)\n",
    "# Need to increase precision over default for this narrow line to make fit work well\n",
    "mylevmar = optmethods.LevMar()\n",
    "mylevmar.config['epsfcn'] = 1e-10\n",
    "fit = Fit(d, howwide, method=mylevmar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.plot_data('fake_gauss')\n",
    "ax = plt.gca()\n",
    "ax.plot(pl.x, pl.y, label='Input RMF model')\n",
    "ax.plot(pl.x, howwide(pl.x), label='Gaussian fit')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()\n",
    "out = ax.set_ylim(500, 1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows the Gaussian fit to the simulated line (note that the y-axis is logarithmic now). The fit does a reasonable job at describing the line core and thus can be used to calculate $R$, but the line has extended wings. (The RMF is generated from a model that has both Gaussian and Lorentzian components because a Gaussian alone is insufficient to describe the wings seen in Arcus ray-traces.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'From the line shape, I calculate R= {howwide.pos.val / howwide.fwhm.val:5.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero-order spectra\n",
    "I now repeat the same steps to check a line emission in the zero order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.set_analysis('energy')\n",
    "ui.set_source('fake_gauss0', ui.xsgaussian.g2)\n",
    "g2.LineE = 1.\n",
    "g2.Sigma = 0.001\n",
    "g2.norm = 100000\n",
    "ui.fake_pha('fake_gauss0', arf0, rmf0, 1e6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = ui.get_data_plot('fake_gauss0')\n",
    "d0 = Data1D('verify_R0', pl.x, pl.y)\n",
    "howwide0 = NormGauss1D('verify_R0')\n",
    "howwide0.fwhm = 0.1\n",
    "howwide0.pos=1.1\n",
    "howwide0.ampl = 1e4\n",
    "fit = Fit(d0, howwide0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = plt.plot(pl.x, pl.y, lw=4)\n",
    "out = plt.plot(pl.x, howwide0(pl.x))\n",
    "out = plt.xlabel('Energy (kev)')\n",
    "out = plt.ylabel('Counts/s/keV')\n",
    "out = plt.xlim([0.9, 1.1])\n",
    "out = plt.title('Fitting faked line with a Gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'From the line shape, I calculate FWHM= {howwide0.fwhm.val * 1000:5.0f} eV.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input value for generating the RMF at this energy is 70 eV, so we can be confident that the ARF and RMF are working as intended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A science simulation\n",
    "As an example, I'm going to simulate a young star (BP Tau), applicable to the Arcus science case. For this star, we might want to use Arcus to check the density in the O VII triplet to see if the emission is coronal or comes from the accretion shock, where the densities are so high that the f/i ratio is reduced compared to the low-density coronal environment. This test has been done with XMM-Newton using a 130 ks exposure ([Schmitt et. al, 2005](https://ui.adsabs.harvard.edu/abs/2005A%26A...432L..35S/abstract)), but with Arcus we could do it in a much shorter exposure time and possibly obtains a series of spectra to test for time variability. The input model for BP Tau is taken from [Robrade & Schmitt (2006)](https://ui.adsabs.harvard.edu/abs/2006A%26A...449..737R/abstract)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.set_xsabund('angr')  # Robrade and Schmitt use a mixuture of Anders & Grevesse and Grevesse & Sauval abundances\n",
    "                        # in their paper, but for the purpose of this simulation, we ignore that detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.units as u\n",
    "\n",
    "bptaumodel = ui.xsphabs.abs1 * (ui.xsvapec.v1 + ui.xsvapec.v2 + ui.xsvapec.v3)\n",
    "\n",
    "abs1.nH = 0.15\n",
    "v1.Fe = 0.28\n",
    "v1.Si = 0.14\n",
    "v1.O = 0.62\n",
    "v1.Ne = 1.47\n",
    "# couple all elements\n",
    "for v in [v2, v3]:\n",
    "    for p in v1.pars[1:-1]:  # leave out kT and norm\n",
    "        setattr(v, p.name, getattr(v1, p.name))\n",
    "        \n",
    "v1.kT = 0.2\n",
    "v2.kT = 0.63\n",
    "v3.kT = 2.17\n",
    "\n",
    "# XSPEC APEC normalization is 1e-14 / 4 pi d^2 with d in cm\n",
    "normfac = 1e-14 / (4 * np.pi * ((130 * u.pc).to(u.cm).value)**2)\n",
    "\n",
    "v1.norm = 3.48e52 * normfac\n",
    "v2.norm = 5.28e52 * normfac\n",
    "v3.norm = 10.3e52 * normfac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.notice(None, None)\n",
    "ui.set_source('BPTau', bptaumodel)\n",
    "ui.fake_pha('BPTau', arfd, rmfd, 25e3)\n",
    "ui.set_analysis(\"wave\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.group_width('BPTau', 3)\n",
    "ui.plot_data(\"BPTau\")\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(21.55, 22.15)\n",
    "out = ax.set_ylim(None, .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows an Arcus simulation for a 25 ks observation with no background. The signal is not great because the absorbing column denstiy really matters for the O VII lines, but the lines are clearly detected. The total count numbers are similar to the much longer XMM-Newton observation, but with Arcus, we obtain a much better wavelength resolution, allowing us to test for line shifts. In an accretion model, we might expcct the lines to the red-shifted, but the velocity resolution in XMM is insufficient to test that. Maybe we should re-run our simulation for a slightly longer exposure time to ensure that we won't be limited by counting statistics when the measure the line centroid?\n",
    "\n",
    "However, that is beyond the scope of the current notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further checks\n",
    "Below are a few extra plots that check consistency between different simulations. Since we use different systems to simulate Arcus that makes slightly different assumptions, disagreement between simulations is not necessarily a problem. For example, when extracting data for a different cross-dispersion width or different order sorting, then the total effective area will be somewhat different. So, these curves can give somewhat of an idea how slightly different choices for these parameters change the predicted outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcus.analysis.grid import orders_from_meta\n",
    "from astropy.table import Table\n",
    "import os\n",
    "tarc = Table.read(os.path.join(get_path('arcus'), 'raygridRAeff.fits'))\n",
    "tarc.orders = orders_from_meta(tarc.meta)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot((arf0.x * u.keV).to(u.Angstrom, equivalencies=u.spectral()), arf0.y, label='order 0')\n",
    "ax.plot((arfd.x * u.keV).to(u.Angstrom, equivalencies=u.spectral()), arfd.y, label='dispersed ARF')\n",
    "\n",
    "ax.fill_between(tarc['wave'], np.sum(tarc['Aeff4'][:, tarc.orders != 0], axis=1), \n",
    "                label='photon counting', color='0.7')\n",
    "\n",
    "ax.set_xlabel('wavelength [$\\AA$]')\n",
    "out = ax.set_ylabel('$A_\\mathrm{eff}$ (' + arf0.get_ylabel() + ')')\n",
    "ax.get_xaxis().set_minor_formatter(mpl.ticker.LogFormatterMathtext(labelOnlyBase=False,\n",
    "                                                                   minor_thresholds=(2, .5)))\n",
    "ax.tick_params(axis='x', labelsize=mpl.rcParams['xtick.labelsize'], which='both')\n",
    "out = ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
