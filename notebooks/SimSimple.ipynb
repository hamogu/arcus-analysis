{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulations with a simplified response matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbtemplate import display_header, get_path\n",
    "display_header('SimSimple.ipynb', status='Arcus 2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*I present a simplified response for Arcus simulations, consisting of just four files: ARF/RMF for zero order and ARF/RMF summed over all dispersed orders. For simplicity, I sum the effective area of all dispersed spectra and average the resolving power. Caveats of this procedure are discussed below, as well has an example of a science simulation.*\n",
    "\n",
    "<div style=\"background-color:orange;font-weight:bold\">\n",
    "If you are reading a static version of this document (e.g. as a readme distributed with arf/rmf files), check <a href=\"https://space.mit.edu/home/guenther/ARCUS/SimSimple.html\">https://space.mit.edu/home/guenther/ARCUS/SimSimple.html</a> for updates.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The need for a simple simulations approach\n",
    "Arcus has four different channels, and in each channel we detect > 15 dispsered orders. Since Arcus has two cameras, some of the signal is detected quite close to the zero order and has resolving powers $R$ of just a few hundred, while most of the signal is dispersed to much larger distances, where we expect to reach resolving powers > 3500. For each order, $R$ changes with wavelegth, and at any given wavelength, we will detect signal in different orders simultaneously at different values of $R$.\n",
    "\n",
    "To make matters more complicated, order-sorting is not perfect and significant order confusion will appear, i.e. in order -5, we will also see some signal from order -4 and -6, which is dispersed in a different way. Thus, the full ARF/RMF set to simulate all this needs > 180 ARF/RMF pairs (4 channels x 15 orders x 3, where the last factor of three acounts for the extracted order and the interloper orders from insufficient order sorting). This clearly is too complicated for most simulations. Thus, I provide here a simplified set of ARF/RMF that averages over all grating orders.\n",
    "\n",
    "## Caveats\n",
    "By averaging, we loose some information and brush over some important science implications. However, I expect that the ARF and RMF files presented here will be sufficient to study the majority of science cases.\n",
    "\n",
    "### Reduced peak resolving power, but overestiamte of effective area at intermediate resolving power\n",
    "I add up effective areas and average $R$ over all relevant orders (using the effective area in each order to weight the  average). Before averaging, some orders provide a better $R$, sometimes significantly so. For example, at 20 Å, Arcus will see several orders with different $R$. For a science investigation that needs to separate two close emission lines, the *average* resolving power might be insufficient, but it maybe could still be done by using only the order that provides the best $R$ (at the cost of a lower effective area). Such a science case needs to be simulated using \"per order\" arf and rmf files. On the other hand, not all orders have the average $R$. A science investigation that requires $R = R_\\mathrm{average}$, will find that in practice some order have higher and some orders have lower $R$. If the orders with lower $R$ are insufficient and only some orders can be used, then the exposure time needs to be longer than simulated with the ARF and RMF presented here.\n",
    "\n",
    "### Order confusion\n",
    "Dispersed Arcus orders will land at the same physical location of the detector and orders need to be sorted using the CCD energy resolution. Since orders are closely spaced in energy space, this order sorting is not easy. Either significant effective area is lost by extracting only very narrow regions in energy space (up to factors of a few in the most extreme scenarios!) or a significant fraction (20% for some scenarios with broad order-sorting regions) of the photons are sorted into the wrong order. This is not as much a problem for emission line sources since comparison of different orders can help to identify lines seen in the wrong order, but for sources with absorption lines in strong continuum, this will effectively act as an extra background, increases in Poisson noise in the continuum measurement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is included in the ARF and RMF?\n",
    "\n",
    "ARF and RMF are calculated based on MARXS ray-tracing. Details of this ray-tracing are described at [Moritz home page](https://space.mit.edu/home/guenther/ARCUS/index.html). In short, the procedure is as follows: A ray-trace simulation is run for a monoenergetic point source at the nominal aimpoint position for a large number of photons. These photons are then propagated through a simple mirror model, and the gratings to the CCDs. The ratio of the number of input photons vs. the number of detected photons gives the ARF. The spatial distribution can be fitted and gives the input to the RMF. Simulations are run using a large number of photons on a relatively coarse grid (1 Å). That grid is sufficient to determine the factors that depend mostly on the geometry (e.g. the shadows cast by the grating support structure). The spot sizes are fitted with a combination of Gaussian and Lorentian components and stored in LSFPARM files in exactly the same format that the Chandra CALDB uses for this purpose. When generating the RMF on an arbitary energy grid, these factors are interpolated. For the ARF, the \"geometric\" factors from the ray-trace are interpolated on the new energy grid, the position of the CCD edges in wavelength space is calcualted analytically, and then multiplied by the factors that depend only on the photons energy (such as the QE od the CCDs). The latter factors are given at a much better energy resolution. Thus, the resulting ARF will properly describe sharp features such as edges in the CCD response, but do not have the same random noise that would happen if the ARF and RMF files were constructed from Monte-Carlo simulations are that run independently for every wavelength bin. (Also, this approach requires several orders of magnitude less computing time.)\n",
    "\n",
    "The follwing effects are included in ARF and RMF:\n",
    "\n",
    "- Sum of effective area for order 2, 1, and -1 to -11 (0 order is treated separately)\n",
    "- Arcus 2021 SPO size and location \n",
    "- SPO coating\n",
    "- SPO in-plane and off-plane Gaussian scatter\n",
    "- 4 mu CAT gratings with nominal 1.8 deg blaze (CAT locations from Ed Hertz) \n",
    "- 4 channels, offset such that chip gaps never overlap (channel placement from optics telecon in Dec 2020),\n",
    "- newest filter and CCD QE curves by Eric Miller \n",
    "- contamination estimate by Meg \n",
    "- all geometric shadowing (from CAT grating mount under SPO) \n",
    "- CAT grating L1 and L2 blockage \n",
    "- L1 cross-dispersion and L2 dispersion \n",
    "- nominal residual pointing jitter (=uncertainty in pointing knowlege), but no jitter beyond that (i.e. constant   aspect solution, so chip-gaps are not filled in by jitter)\n",
    "- contamination of order by incomplete order sorting\n",
    "- mechnical misalignment according to Arcus alignment budget\n",
    "\n",
    "\n",
    "## What it not included?\n",
    "\n",
    "- order sorting and lossing due to OSIP filtering\n",
    "- choice of spatial extraction regions. Currently, I'm using all photons\n",
    " that are not cross-dispersed, but that is at the same time \n",
    "too restrictive (for low background, one can get more signal by\n",
    "including a wider region), and not ambitious enough (R could be enhanced\n",
    "by extracting a narrower region).\n",
    "\n",
    "- chip edges are included, but treatment of the exact edge is not fully\n",
    "correct (should not be this sharp due to finite RMF)\n",
    "\n",
    "- cross-channel contamination\n",
    "\n",
    "- off-axis / extended sources\n",
    "- CCD details like read-out streaks, hot pixels etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do ARF and RMF look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sherpa.astro import ui\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve labelling of log scales\n",
    "mpl.rcParams['axes.formatter.min_exponent'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arfrmfpath = '../../arfrmf/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arf0 = ui.unpack_arf(arfrmfpath + 'order_0_chan_all.arf')\n",
    "arfd = ui.unpack_arf(arfrmfpath + 'all_dispersed.arf')\n",
    "rmf0 = ui.unpack_rmf(arfrmfpath + 'order_0_chan_all.rmf')\n",
    "rmfd = ui.unpack_rmf(arfrmfpath + 'all_dispersed.rmf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.semilogx(arf0.x, arf0.y, label='order 0')\n",
    "ax.semilogx(arfd.x, arfd.y, label='dispesed')\n",
    "ax.set_xlabel(arf0.get_xlabel())\n",
    "ax.set_ylabel(arf0.get_ylabel())\n",
    "ax.get_xaxis().set_minor_formatter(mpl.ticker.LogFormatterMathtext(labelOnlyBase=False,\n",
    "                                                                   minor_thresholds=(2, .5)))\n",
    "ax.tick_params(axis='x', labelsize=mpl.rcParams['xtick.labelsize'], which='both')\n",
    "out = ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure shows the effective area for the dispersed signal and the direct light (0 order)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The figure shows five exemplary line spread functions for the averaged RMF of the dispersed orders. Note that the y axis is logarithmic. The line spread function is narrow for low energies (large wavelength) that are seen in the higher orders and wider for higher energies, that are only see in order 1 or 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the spectral resolution\n",
    "As a simple illustration of the spectral resolution, I fake a single, very narrow emission lines. Then, I can check $R=\\frac{\\lambda}{\\Delta\\lambda}$ where we take the FWHM of the line as $\\Delta\\lambda$. For this and all following simulations, I'm using [Sherpa](https://cxc.cfa.harvard.edu/sherpa/), which is distrubuted with [CIAO](https://cxc.cfa.harvard.edu/ciao/). Use the \"toggle on/of code\" button on the top of this page ([interactive version](https://space.mit.edu/home/guenther/ARCUS/SimSimple.html)) to see the commands. Of course, this is just an example. The ARF and RMF files are OGIP compliant and any other X-ray modelling package (XSPEC, ISIS, SPEX, ...) should work similarly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.set_source('fake_gauss', ui.gauss1d.g1)\n",
    "g1.pos = 20.\n",
    "g1.fwhm = 0.0001\n",
    "g1.ampl = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set analysis only works if a dataset has been loaded already, so we make one first\n",
    "# and then overwrite it again after calling \"set_analysis\"\n",
    "ui.fake_pha('fake_gauss', arfd, rmfd, 5)\n",
    "ui.set_analysis(\"wave\")\n",
    "ui.fake_pha('fake_gauss', arfd, rmfd, 1e8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.notice(19.95, 20.05)\n",
    "ui.ignore(None, 19.95)\n",
    "ui.ignore(20.05, None)\n",
    "ui.plot_fit('fake_gauss')\n",
    "ax = plt.gca()\n",
    "out = ax.set_xlim(19.975, 20.025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows a fakes line at 20 Å. Orange is the input model (in the binning used in the ARF and RMF) and blue are simulated photons counts, where I have simulated so many photons, that the Poisson noise is negligible. I am now taking the x (wavelength) and y (count rate) numbers in the plot above and fit a Gaussian line to it without folding it through the RMF. That way, I can measure the observed line profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = ui.get_data_plot('fake_gauss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sherpa.models import NormGauss1D\n",
    "from sherpa import stats\n",
    "from sherpa import optmethods\n",
    "from sherpa.data import Data1D\n",
    "from sherpa.fit import Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Data1D('verify_R', pl.x, pl.y)\n",
    "howwide = NormGauss1D('verify_R')\n",
    "howwide.fwhm = 0.001\n",
    "howwide.pos=20.\n",
    "fit = Fit(d, howwide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.plot_data('fake_gauss')\n",
    "ax = plt.gca()\n",
    "ax.plot(pl.x, howwide(pl.x))\n",
    "ax.set_yscale('log')\n",
    "out = ax.set_ylim(50, 1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows the Gaussian fit to the simulated line (note that the y-axis is logarithmic now). The fit does a reasonable job at describing the line core and thus cna be used to calculate $R$, but the line has extended wings. (The RMF is generated from a model that has both Gaussian and Lorentzian components because a Gaussian alone is insufficient to describe the wings seen in Arcus ray-traces.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f'From the line shape, I calculate R= {howwide.pos.val / howwide.fwhm.val:5.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A science simulation\n",
    "As an example, I'm going to simulate a young star (BP Tau), applicable to the Arcus science case. For this star, we might want to use Arcus to check the density in the O VII triplet to see if the emission is coronal or comes from the accretion shock, where the densities are so high the the f/i ratio is reduced compared to the low-density coronal environment. This test has been done with XMM-Newton using a 130 ks exposure ([Schmitt et. al, 2005](https://ui.adsabs.harvard.edu/abs/2005A%26A...432L..35S/abstract)), but with Arcus we could do it in a much shorter exposure time to test for time variability. The input model for BP Tau is taken from [Robrade & Schmitt (2006)](https://ui.adsabs.harvard.edu/abs/2006A%26A...449..737R/abstract)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.set_xsabund('angr')  # Robrade and Schmitt use a mixuture of Anders & Grevesse and Grevesse & Sauval abundances\n",
    "                        # in their paper, but for the purposes of this simulation, we ignore that detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.units as u\n",
    "\n",
    "bptaumodel = ui.xsphabs.abs1 * (ui.xsvapec.v1 + ui.xsvapec.v2 + ui.xsvapec.v3)\n",
    "\n",
    "abs1.nH = 0.15\n",
    "v1.Fe = 0.28\n",
    "v1.Si = 0.14\n",
    "v1.O = 0.62\n",
    "v1.Ne = 1.47\n",
    "# couple all elements\n",
    "for v in [v2, v3]:\n",
    "    for p in v1.pars[1:-1]:  # leave out kT and norm\n",
    "        setattr(v, p.name, getattr(v1, p.name))\n",
    "        \n",
    "v1.kT = 0.2\n",
    "v2.kT = 0.63\n",
    "v3.kT = 2.17\n",
    "\n",
    "# XSPEC APEC normalization is 1e-14 / 4 pi d^2 with d in cm\n",
    "normfac = 1e-14 / (4 * np.pi * ((130 * u.pc).to(u.cm).value)**2)\n",
    "\n",
    "v1.norm = 3.48e52 * normfac\n",
    "v2.norm = 5.28e52 * normfac\n",
    "v3.norm = 10.3e52 * normfac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.set_source('BPTau', bptaumodel)\n",
    "ui.fake_pha('BPTau', arfd, rmfd, 25e3)\n",
    "ui.set_analysis(\"wave\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui.group_width('BPTau', 3)\n",
    "ui.plot_data(\"BPTau\")\n",
    "ax = plt.gca()\n",
    "ax.set_xlim(21.55, 22.15)\n",
    "ax.set_ylim(None, .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows an Arcus simulation for a 25 ks observation. The signal is not great because the absorbing column denstiy really matters for the O VII lines, but the lines are clearly detected. The total count numbers are similar to the much longer XMM-Newton observation, but with Arcus, we obtain a much better wavelength resolution, allowing us to test for line shifts. In an accretion model, we might expact the lines to the red-shifted, but the velocity resolution in XMM is insufficient to test that. Maybe we should re-run our simulation for a slightl longer exposure time to ensure that we won't be limited by counting statistics when the measure the line centroid?\n",
    "\n",
    "However, that is beyond the scope of the current notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
